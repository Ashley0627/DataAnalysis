{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Logistic Regression Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist 是机构缩写，研究算法\n",
    "# 数据 标准化，测试算法\n",
    "# mnist 手写数字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-8cc86c35fe5b>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From D:\\anacondna\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From D:\\anacondna\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From D:\\anacondna\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From D:\\anacondna\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\anacondna\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x000001C4069CBC88>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x000001C4069CBCC0>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x000001C4069D7828>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('./')\n",
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = mnist.train.images\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 3, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c408c0af98>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[-3].reshape(28,28,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\anacondna\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('./',one_hot= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one -hot 热，独热编码\n",
    "# 概率\n",
    "mnist.train.labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.,  1.,  3.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([-3,1,3.0])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00217852 0.11894324 0.87887824]\n"
     ]
    }
   ],
   "source": [
    "b = tf.nn.softmax(a)\n",
    "b\n",
    "\n",
    "# softmax将数据转化成了概率，同时概率之和是1\n",
    "# 支持向量机，专一\n",
    "# softmax，所有都不放过，计算概率\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.125, 2.   , 8.   ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00217852, 0.11894324, 0.87887824])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.e**a/(np.e**a).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 声明graph、Softmax、最小化Cross Entroy（交叉熵）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters\n",
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(dtype=tf.float64,shape = [None,784])\n",
    "\n",
    "y = tf.placeholder(dtype=tf.float64,shape = [None,10])\n",
    "\n",
    "W = tf.Variable(initial_value=tf.random_normal(shape =[784,10],dtype = tf.float64),dtype=tf.float64)\n",
    "\n",
    "b = tf.Variable(initial_value=tf.random_normal(shape = [10],dtype = tf.float64),dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Softmax_4:0' shape=(?, 10) dtype=float64>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrix multipy 矩阵乘法\n",
    "pred = tf.matmul(X,W) + b\n",
    "y_ = tf.nn.softmax(pred)\n",
    "# 概率 每个样本概率和等于1\n",
    "# 预测，非真实分布\n",
    "y_\n",
    "\n",
    "# y真实分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mean_1:0' shape=() dtype=float64>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 交叉熵进行计算\n",
    "cost = tf.reduce_mean(tf.reduce_sum(tf.multiply(y,tf.log(1/y_)),axis = -1))\n",
    "cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd = tf.train.GradientDescentOptimizer(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交叉熵最小\n",
    "optimizer = gd.minimize(cost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化TensorFlow进行运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(550, 784)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(550, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train,y_train  = mnist.train.next_batch(550)\n",
    "\n",
    "display(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "循环0次，损失函数值是：9.75\n",
      "循环1次，损失函数值是：8.89\n",
      "循环2次，损失函数值是：7.69\n",
      "循环3次，损失函数值是：6.75\n",
      "循环4次，损失函数值是：5.91\n",
      "循环5次，损失函数值是：5.55\n",
      "循环6次，损失函数值是：4.69\n",
      "循环7次，损失函数值是：4.64\n",
      "循环8次，损失函数值是：4.14\n",
      "循环9次，损失函数值是：3.84\n",
      "循环10次，损失函数值是：3.28\n",
      "循环11次，损失函数值是：3.59\n",
      "循环12次，损失函数值是：3.39\n",
      "循环13次，损失函数值是：3.19\n",
      "循环14次，损失函数值是：2.89\n",
      "循环15次，损失函数值是：2.83\n",
      "循环16次，损失函数值是：2.54\n",
      "循环17次，损失函数值是：2.31\n",
      "循环18次，损失函数值是：2.54\n",
      "循环19次，损失函数值是：2.49\n",
      "循环20次，损失函数值是：2.31\n",
      "循环21次，损失函数值是：2.15\n",
      "循环22次，损失函数值是：2.27\n",
      "循环23次，损失函数值是：2.11\n",
      "循环24次，损失函数值是：2.04\n",
      "循环25次，损失函数值是：1.82\n",
      "循环26次，损失函数值是：1.89\n",
      "循环27次，损失函数值是：1.99\n",
      "循环28次，损失函数值是：1.67\n",
      "循环29次，损失函数值是：1.77\n",
      "循环30次，损失函数值是：1.80\n",
      "循环31次，损失函数值是：1.61\n",
      "循环32次，损失函数值是：1.46\n",
      "循环33次，损失函数值是：1.61\n",
      "循环34次，损失函数值是：1.40\n",
      "循环35次，损失函数值是：1.50\n",
      "循环36次，损失函数值是：1.46\n",
      "循环37次，损失函数值是：1.47\n",
      "循环38次，损失函数值是：1.29\n",
      "循环39次，损失函数值是：1.52\n",
      "循环40次，损失函数值是：1.65\n",
      "循环41次，损失函数值是：1.50\n",
      "循环42次，损失函数值是：1.78\n",
      "循环43次，损失函数值是：1.51\n",
      "循环44次，损失函数值是：1.44\n",
      "循环45次，损失函数值是：1.54\n",
      "循环46次，损失函数值是：1.52\n",
      "循环47次，损失函数值是：1.59\n",
      "循环48次，损失函数值是：1.35\n",
      "循环49次，损失函数值是：1.56\n",
      "循环50次，损失函数值是：1.37\n",
      "循环51次，损失函数值是：1.10\n",
      "循环52次，损失函数值是：1.14\n",
      "循环53次，损失函数值是：1.03\n",
      "循环54次，损失函数值是：1.26\n",
      "循环55次，损失函数值是：1.12\n",
      "循环56次，损失函数值是：1.32\n",
      "循环57次，损失函数值是：1.23\n",
      "循环58次，损失函数值是：1.17\n",
      "循环59次，损失函数值是：1.08\n",
      "循环60次，损失函数值是：0.98\n",
      "循环61次，损失函数值是：1.22\n",
      "循环62次，损失函数值是：1.18\n",
      "循环63次，损失函数值是：1.11\n",
      "循环64次，损失函数值是：1.19\n",
      "循环65次，损失函数值是：1.16\n",
      "循环66次，损失函数值是：1.07\n",
      "循环67次，损失函数值是：1.38\n",
      "循环68次，损失函数值是：1.16\n",
      "循环69次，损失函数值是：0.87\n",
      "循环70次，损失函数值是：1.09\n",
      "循环71次，损失函数值是：1.14\n",
      "循环72次，损失函数值是：0.90\n",
      "循环73次，损失函数值是：1.19\n",
      "循环74次，损失函数值是：1.04\n",
      "循环75次，损失函数值是：1.23\n",
      "循环76次，损失函数值是：1.20\n",
      "循环77次，损失函数值是：1.07\n",
      "循环78次，损失函数值是：1.04\n",
      "循环79次，损失函数值是：0.86\n",
      "循环80次，损失函数值是：0.94\n",
      "循环81次，损失函数值是：1.10\n",
      "循环82次，损失函数值是：0.79\n",
      "循环83次，损失函数值是：1.04\n",
      "循环84次，损失函数值是：1.09\n",
      "循环85次，损失函数值是：1.00\n",
      "循环86次，损失函数值是：1.01\n",
      "循环87次，损失函数值是：0.91\n",
      "循环88次，损失函数值是：1.00\n",
      "循环89次，损失函数值是：1.16\n",
      "循环90次，损失函数值是：1.08\n",
      "循环91次，损失函数值是：1.11\n",
      "循环92次，损失函数值是：1.12\n",
      "循环93次，损失函数值是：0.89\n",
      "循环94次，损失函数值是：0.82\n",
      "循环95次，损失函数值是：0.81\n",
      "循环96次，损失函数值是：1.03\n",
      "循环97次，损失函数值是：0.93\n",
      "循环98次，损失函数值是：0.85\n",
      "循环99次，损失函数值是：0.98\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(100):\n",
    "        for j in range(100):\n",
    "            X_train,y_train = mnist.train.next_batch(550)\n",
    "            optimizer_,cost_ = sess.run(fetches = [optimizer,cost],feed_dict = {X:X_train,y:y_train})\n",
    "        print('循环%d次，损失函数值是：%0.2f'%(i,cost_)) \n",
    "        \n",
    "#         9,19,29,……99\n",
    "        if (i+1)%10 == 0:\n",
    "            saver.save(sess,save_path='./model/estimator',global_step=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/estimator-99\n",
      "循环100次，损失函数值是：0.78\n",
      "循环101次，损失函数值是：1.07\n",
      "循环102次，损失函数值是：0.90\n",
      "循环103次，损失函数值是：1.00\n",
      "循环104次，损失函数值是：1.13\n",
      "循环105次，损失函数值是：0.84\n",
      "循环106次，损失函数值是：0.86\n",
      "循环107次，损失函数值是：0.77\n",
      "循环108次，损失函数值是：1.05\n",
      "循环109次，损失函数值是：0.87\n",
      "循环110次，损失函数值是：0.78\n",
      "循环111次，损失函数值是：0.92\n",
      "循环112次，损失函数值是：0.94\n",
      "循环113次，损失函数值是：0.92\n",
      "循环114次，损失函数值是：0.80\n",
      "循环115次，损失函数值是：1.03\n",
      "循环116次，损失函数值是：0.86\n",
      "循环117次，损失函数值是：0.88\n",
      "循环118次，损失函数值是：0.71\n",
      "循环119次，损失函数值是：0.99\n",
      "循环120次，损失函数值是：0.81\n",
      "循环121次，损失函数值是：0.89\n",
      "循环122次，损失函数值是：0.92\n",
      "循环123次，损失函数值是：1.08\n",
      "循环124次，损失函数值是：0.80\n",
      "循环125次，损失函数值是：0.70\n",
      "循环126次，损失函数值是：0.89\n",
      "循环127次，损失函数值是：0.79\n",
      "循环128次，损失函数值是：0.80\n",
      "循环129次，损失函数值是：0.63\n",
      "循环130次，损失函数值是：1.01\n",
      "循环131次，损失函数值是：0.95\n",
      "循环132次，损失函数值是：0.80\n",
      "循环133次，损失函数值是：0.86\n",
      "循环134次，损失函数值是：0.92\n",
      "循环135次，损失函数值是：0.85\n",
      "循环136次，损失函数值是：0.70\n",
      "循环137次，损失函数值是：0.79\n",
      "循环138次，损失函数值是：0.89\n",
      "循环139次，损失函数值是：0.88\n",
      "循环140次，损失函数值是：0.74\n",
      "循环141次，损失函数值是：0.76\n",
      "循环142次，损失函数值是：0.68\n",
      "循环143次，损失函数值是：0.83\n",
      "循环144次，损失函数值是：0.67\n",
      "循环145次，损失函数值是：0.88\n",
      "循环146次，损失函数值是：0.73\n",
      "循环147次，损失函数值是：0.94\n",
      "循环148次，损失函数值是：0.88\n",
      "循环149次，损失函数值是：0.73\n",
      "循环150次，损失函数值是：0.65\n",
      "循环151次，损失函数值是：0.91\n",
      "循环152次，损失函数值是：0.65\n",
      "循环153次，损失函数值是：0.71\n",
      "循环154次，损失函数值是：0.91\n",
      "循环155次，损失函数值是：0.80\n",
      "循环156次，损失函数值是：0.73\n",
      "循环157次，损失函数值是：0.77\n",
      "循环158次，损失函数值是：0.74\n",
      "循环159次，损失函数值是：0.70\n",
      "循环160次，损失函数值是：0.83\n",
      "循环161次，损失函数值是：0.94\n",
      "循环162次，损失函数值是：0.72\n",
      "循环163次，损失函数值是：0.73\n",
      "循环164次，损失函数值是：0.84\n",
      "循环165次，损失函数值是：0.70\n",
      "循环166次，损失函数值是：0.70\n",
      "循环167次，损失函数值是：0.72\n",
      "循环168次，损失函数值是：0.76\n",
      "循环169次，损失函数值是：0.91\n",
      "循环170次，损失函数值是：0.85\n",
      "循环171次，损失函数值是：0.78\n",
      "循环172次，损失函数值是：0.80\n",
      "循环173次，损失函数值是：0.77\n",
      "循环174次，损失函数值是：0.62\n",
      "循环175次，损失函数值是：0.75\n",
      "循环176次，损失函数值是：0.77\n",
      "循环177次，损失函数值是：0.81\n",
      "循环178次，损失函数值是：0.80\n",
      "循环179次，损失函数值是：0.80\n",
      "循环180次，损失函数值是：0.68\n",
      "循环181次，损失函数值是：0.79\n",
      "循环182次，损失函数值是：0.72\n",
      "循环183次，损失函数值是：0.80\n",
      "循环184次，损失函数值是：0.66\n",
      "循环185次，损失函数值是：0.68\n",
      "循环186次，损失函数值是：0.89\n",
      "循环187次，损失函数值是：0.79\n",
      "循环188次，损失函数值是：0.75\n",
      "循环189次，损失函数值是：0.83\n",
      "循环190次，损失函数值是：0.64\n",
      "循环191次，损失函数值是：0.62\n",
      "循环192次，损失函数值是：0.84\n",
      "循环193次，损失函数值是：0.69\n",
      "循环194次，损失函数值是：0.70\n",
      "循环195次，损失函数值是：0.63\n",
      "循环196次，损失函数值是：0.80\n",
      "循环197次，损失函数值是：0.75\n",
      "循环198次，损失函数值是：0.65\n",
      "循环199次，损失函数值是：0.71\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess,'./model/estimator-99')\n",
    "    \n",
    "    for i in range(100,200):\n",
    "        for j in range(100):\n",
    "            X_train,y_train = mnist.train.next_batch(550)\n",
    "            optimizer_,cost_ = sess.run(fetches = [optimizer,cost],feed_dict = {X:X_train,y:y_train})\n",
    "        print('循环%d次，损失函数值是：%0.2f'%(i,cost_)) \n",
    "        \n",
    "#         9,19,29,……99\n",
    "        if (i+1)%10 == 0:\n",
    "            saver.save(sess,save_path='./model/estimator',global_step=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/estimator-199\n",
      "循环100次，损失函数值是：0.59\n",
      "循环101次，损失函数值是：0.64\n",
      "循环102次，损失函数值是：0.69\n",
      "循环103次，损失函数值是：0.70\n",
      "循环104次，损失函数值是：0.63\n",
      "循环105次，损失函数值是：0.66\n",
      "循环106次，损失函数值是：0.76\n",
      "循环107次，损失函数值是：0.87\n",
      "循环108次，损失函数值是：0.62\n",
      "循环109次，损失函数值是：0.72\n",
      "循环110次，损失函数值是：0.62\n",
      "循环111次，损失函数值是：0.83\n",
      "循环112次，损失函数值是：0.66\n",
      "循环113次，损失函数值是：0.70\n",
      "循环114次，损失函数值是：0.79\n",
      "循环115次，损失函数值是：0.71\n",
      "循环116次，损失函数值是：0.77\n",
      "循环117次，损失函数值是：0.90\n",
      "循环118次，损失函数值是：0.71\n",
      "循环119次，损失函数值是：0.75\n",
      "循环120次，损失函数值是：0.69\n",
      "循环121次，损失函数值是：0.73\n",
      "循环122次，损失函数值是：0.56\n",
      "循环123次，损失函数值是：0.62\n",
      "循环124次，损失函数值是：0.71\n",
      "循环125次，损失函数值是：0.83\n",
      "循环126次，损失函数值是：0.63\n",
      "循环127次，损失函数值是：0.71\n",
      "循环128次，损失函数值是：0.71\n",
      "循环129次，损失函数值是：0.66\n",
      "循环130次，损失函数值是：0.70\n",
      "循环131次，损失函数值是：0.85\n",
      "循环132次，损失函数值是：0.78\n",
      "循环133次，损失函数值是：0.59\n",
      "循环134次，损失函数值是：0.67\n",
      "循环135次，损失函数值是：0.67\n",
      "循环136次，损失函数值是：0.84\n",
      "循环137次，损失函数值是：0.48\n",
      "循环138次，损失函数值是：0.45\n",
      "循环139次，损失函数值是：0.67\n",
      "循环140次，损失函数值是：0.62\n",
      "循环141次，损失函数值是：0.61\n",
      "循环142次，损失函数值是：0.60\n",
      "循环143次，损失函数值是：0.76\n",
      "循环144次，损失函数值是：0.76\n",
      "循环145次，损失函数值是：0.73\n",
      "循环146次，损失函数值是：0.69\n",
      "循环147次，损失函数值是：0.57\n",
      "循环148次，损失函数值是：0.68\n",
      "循环149次，损失函数值是：0.62\n",
      "循环150次，损失函数值是：0.70\n",
      "循环151次，损失函数值是：0.50\n",
      "循环152次，损失函数值是：0.65\n",
      "循环153次，损失函数值是：0.69\n",
      "循环154次，损失函数值是：0.74\n",
      "循环155次，损失函数值是：0.62\n",
      "循环156次，损失函数值是：0.69\n",
      "循环157次，损失函数值是：0.45\n",
      "循环158次，损失函数值是：0.53\n",
      "循环159次，损失函数值是：0.65\n",
      "循环160次，损失函数值是：0.76\n",
      "循环161次，损失函数值是：0.67\n",
      "循环162次，损失函数值是：0.69\n",
      "循环163次，损失函数值是：0.50\n",
      "循环164次，损失函数值是：0.68\n",
      "循环165次，损失函数值是：0.52\n",
      "循环166次，损失函数值是：0.74\n",
      "循环167次，损失函数值是：0.51\n",
      "循环168次，损失函数值是：0.62\n",
      "循环169次，损失函数值是：0.69\n",
      "循环170次，损失函数值是：0.72\n",
      "循环171次，损失函数值是：0.68\n",
      "循环172次，损失函数值是：0.64\n",
      "循环173次，损失函数值是：0.66\n",
      "循环174次，损失函数值是：0.74\n",
      "循环175次，损失函数值是：0.61\n",
      "循环176次，损失函数值是：0.71\n",
      "循环177次，损失函数值是：0.71\n",
      "循环178次，损失函数值是：0.60\n",
      "循环179次，损失函数值是：0.59\n",
      "循环180次，损失函数值是：0.60\n",
      "循环181次，损失函数值是：0.69\n",
      "循环182次，损失函数值是：0.64\n",
      "循环183次，损失函数值是：0.61\n",
      "循环184次，损失函数值是：0.68\n",
      "循环185次，损失函数值是：0.58\n",
      "循环186次，损失函数值是：0.63\n",
      "循环187次，损失函数值是：0.63\n",
      "循环188次，损失函数值是：0.51\n",
      "循环189次，损失函数值是：0.57\n",
      "循环190次，损失函数值是：0.71\n",
      "循环191次，损失函数值是：0.62\n",
      "循环192次，损失函数值是：0.56\n",
      "循环193次，损失函数值是：0.56\n",
      "循环194次，损失函数值是：0.64\n",
      "循环195次，损失函数值是：0.71\n",
      "循环196次，损失函数值是：0.75\n",
      "循环197次，损失函数值是：0.66\n",
      "循环198次，损失函数值是：0.68\n",
      "循环199次，损失函数值是：0.47\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess,'./model/estimator-199')\n",
    "    \n",
    "    for i in range(100,200):\n",
    "        for j in range(100):\n",
    "            X_train,y_train = mnist.train.next_batch(550)\n",
    "            optimizer_,cost_ = sess.run(fetches = [optimizer,cost],feed_dict = {X:X_train,y:y_train})\n",
    "        print('循环%d次，损失函数值是：%0.2f'%(i,cost_)) \n",
    "        \n",
    "#         9,19,29,……99\n",
    "        if (i+1)%10 == 0:\n",
    "            saver.save(sess,save_path='./model/estimator',global_step=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算准确率  \n",
    "#### argmax cast  reduce_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/estimator-199\n",
      "算法预测准确率：  0.835\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,save_path='./model/estimator-199')\n",
    "    \n",
    "    X_test,y_test = mnist.test.next_batch(2000)\n",
    "    \n",
    "#     计算准确率\n",
    "    prob_ = sess.run(fetches = y_,feed_dict= {X:X_test})\n",
    "#     prob_类别\n",
    "    prob_ = np.argmax(prob_,axis = -1)\n",
    "    \n",
    "    y_test = np.argmax(y_test,axis = -1)\n",
    "    print('算法预测准确率： ',(prob_ == y_test).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/estimator-199\n",
      "算法预测准确率：  0.862\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,save_path='./model/estimator-199')\n",
    "    \n",
    "    X_test,y_test = mnist.test.next_batch(2000)\n",
    "    \n",
    "#     计算准确率\n",
    "    prob_ = sess.run(fetches = y_,feed_dict= {X:X_test})\n",
    "#     prob_类别\n",
    "    prob_ = np.argmax(prob_,axis = -1)\n",
    "    \n",
    "    y_test = np.argmax(y_test,axis = -1)\n",
    "    print('算法预测准确率： ',(prob_ == y_test).mean())"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
